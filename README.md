<h1 align =center> IBM-Z-Datathon </h1>

## TEAM NAME: BREAD AND BUTTER
## TEAM NO: SAV109
## TEAM MEMBERS: 
### HARISH R (TEAM LEADER)
### LAAKSHIT D
### KAMALESH SV
### RISHI M

# PROBLEM STATEMENT:
Cyberbullying has become a pervasive issue in the digital age, especially among young people on social media platforms. Harmful online behavior, including harassment, insults, and threats, can severely impact mental health, leading to anxiety, depression, and even tragic outcomes like self-harm or suicide. Given the vast volume of online content generated daily, it is difficult to manually monitor and detect cyberbullying in real-time. Current efforts to address this issue are reactive and resource-intensive, often leaving harmful content unaddressed for too long.

# SOLUTION:
To develop a machine learning model using Natural Language Processing (NLP) to detect and flag cyberbullying in online text in real-time. The model will analyze social media posts, chat messages, or online comments for negative language patterns, harmful sentiment, and contextual indicators of bullying. By training the model on pre-existing datasets from kaggle that contain examples of both harmful and neutral content, we can create a classifier capable of identifying bullying behavior with high accuracy.

The system will automatically scan text for harmful expressions, insults, or threats and classify each message as either "bullying" or "non-bullying." This flagged content can then be sent to moderators or automated systems for review and action, enabling timely intervention before further harm occurs. The model can be fine-tuned to detect various forms of bullying, including threats, harassment, and exclusionary behavior, across multiple platforms.

By providing a scalable, automated approach to content moderation, this solution aims to reduce the prevalence of cyberbullying, safeguard users' mental health, and promote safer online interactions.

# OUTPUT:

# RESULT:
Thus,the output is verified successfully
